
# ğŸ§  Minimal Autodiff Engine (From Scratch)

This repository contains my implementation of:

- ğŸ” Forward-Mode Automatic Differentiation (Dual Numbers)
- ğŸ”„ Reverse-Mode Automatic Differentiation (Backpropagation)
- ğŸ§® 2-Layer MLP built using the autodiff engine

---

## ğŸ“‚ Project Structure


```
autodiff-engine/
â”‚
â”œâ”€â”€ forward_mode/        # Dual number implementation
â”œâ”€â”€ reverse_mode/        # Computation graph + backprop
â”œâ”€â”€ two_layer_mlp/       # Neural network using autodiff

```

---

## ğŸ¯ Purpose

The goal of this project is to deeply understand:

- Chain rule
- Gradient propagation
- Computation graphs
- Backpropagation
- How frameworks like PyTorch work internally

Everything is implemented from scratch using pure Python.

---

## ğŸš€ Why This Project

Instead of using ML libraries, this project focuses on:

Understand â†’ Implement â†’ Verify â†’ Document

---

## ğŸ›  Tech Stack

- Python
- math module
- numpy (for MLP if used)

---

## ğŸ‘¨â€ğŸ’» Author


**Dola Sreecharan**

Machine Learning Enthusiast  
Focused on building strong mathematical foundations in deep learning.

GitHub: https://github.com/DolaSreecharan


---

